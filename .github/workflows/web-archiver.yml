name: Web Archiver Reusable Workflow

# This workflow is designed to be called from another repository.
on:
  workflow_call:
    inputs:
      artifacts:
        description: >
          A comma‚Äêseparated list of artifacts to archive.
          For example: "https://example.com, r/AskReddit, https://example.com/file.pdf"
        required: true
        type: string
      schedule:
        description: 'Description of the schedule (e.g., "Daily at midnight (UTC)")'
        required: false
        type: string
        default: 'Daily at midnight (UTC)'
    secrets:
      GITHUB_TOKEN:
        required: true

jobs:
  archive:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Install Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y wget curl python3

      - name: Parse Artifacts Input
        id: parse
        run: |
          # Convert the comma-separated input into a list and write to a file.
          IFS=',' read -ra ARTIFACTS <<< "${{ inputs.artifacts }}"
          for artifact in "${ARTIFACTS[@]}"; do
            trimmed=$(echo "$artifact" | xargs)
            echo "$trimmed" >> artifacts_list.txt
          done
          echo "Artifacts to process:"
          cat artifacts_list.txt

      - name: Archive Artifacts and Generate Files
        id: archive_step
        run: |
          # Create directories for archived content and static files.
          mkdir -p archive static

          # Initialize the README and index content.
          README_CONTENT="# Archive Report\n\n## Archived Artifacts:\n"
          INDEX_CONTENT="<html><head><title>Archive Index</title></head><body><h1>Archived Artifacts</h1><ul>"

          # Loop over each artifact.
          while IFS= read -r artifact; do
            echo "Processing artifact: $artifact"
            if [[ "$artifact" =~ ^https?:// ]]; then
              # If the artifact is a URL (website or file), download it.
              FOLDER_NAME=$(echo "$artifact" | awk -F/ '{print $3}')
              TARGET_DIR="archive/${FOLDER_NAME}"
              echo "Downloading URL: $artifact into $TARGET_DIR"
              mkdir -p "$TARGET_DIR"
              # The wget command mirrors the site; adjust options if needed.
              wget --mirror --convert-links --adjust-extension --page-requisites --no-parent "$artifact" -P "$TARGET_DIR"

              README_CONTENT+=" - **$artifact** archived in \`$TARGET_DIR\`\n"
              INDEX_CONTENT+="<li><a href='$TARGET_DIR/index.html'>$artifact</a></li>"

            elif [[ "$artifact" =~ ^r/ ]]; then
              # If the artifact starts with "r/", treat it as a subreddit.
              SUBREDDIT=$(echo "$artifact" | cut -d'/' -f2)
              OUTPUT_FILE="archive/${SUBREDDIT}.json"
              echo "Archiving subreddit: $SUBREDDIT into $OUTPUT_FILE"
              # Placeholder: Replace with actual archiving logic if needed.
              echo "{}" > "$OUTPUT_FILE"

              README_CONTENT+=" - **r/$SUBREDDIT** archived in \`$OUTPUT_FILE\`\n"
              INDEX_CONTENT+="<li><a href='$OUTPUT_FILE'>r/$SUBREDDIT Archive</a></li>"

            else
              echo "Artifact type not recognized: $artifact"
              README_CONTENT+=" - **$artifact**: Unrecognized artifact type.\n"
              INDEX_CONTENT+="<li>$artifact (Unrecognized)</li>"
            fi
          done < artifacts_list.txt

          INDEX_CONTENT+="</ul></body></html>"

          # Write out the generated README and index files.
          echo -e "$README_CONTENT" > README.md
          echo -e "$INDEX_CONTENT" > index.html

          # Append schedule information, a ZIP download link, and a GitHub Pages link to the README.
          echo -e "\n## Schedule\n${{ inputs.schedule }}" >> README.md

          # GitHub automatically provides a ZIP download for the current branch.
          ZIP_URL="https://github.com/${GITHUB_REPOSITORY}/archive/refs/heads/${GITHUB_REF#refs/heads/}.zip"
          echo -e "\n[Download ZIP of Repository]($ZIP_URL)" >> README.md

          # Construct the GitHub Pages URL (adjust if your Pages settings differ).
          REPO_NAME=$(basename "$GITHUB_REPOSITORY")
          OWNER=$(echo "$GITHUB_REPOSITORY" | cut -d'/' -f1)
          PAGES_URL="https://${OWNER}.github.io/${REPO_NAME}/"
          echo -e "\n[View Published GitHub Pages Site]($PAGES_URL)" >> README.md

          # Add a sample static file.
          echo "This is a static file." > static/example.txt

      - name: Commit and Push Changes
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add .
          git commit -m "Update archived artifacts [skip ci]" || echo "No changes to commit"
          git push

      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: .